# Vision Transformer (ViT)

**论文**：*An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale*

## 1. 问题

### 1.1. 概述

Transformer 架构在自然语言处理领域表现优异，并已成为主流架构；但在计算机视觉领域，主流仍是传统的卷积架构，而在大规模图像处理问题上，表现最佳的依旧是经典的 ResNet 等架构。

### 1.2. 重要性

得益于 Transformer 模型的计算效率和可扩展性，如今已能够训练出参数量超过 1000 亿的大型模型，并且随着模型和数据集规模的不断扩大，其性能仍未见饱和迹象。据此可知，Transformer 模型还有极大的潜能可供发掘。

但截止这篇论文发表，许多将类似卷积神经网络的架构与自注意力机制相结合的尝试都未取得良好结果。这些模型在理论上效率很高，但由于采用了专门的注意力模式，未能在现代硬件加速器上实现有效扩展。因此，将标准的 Transformer 直接应用于图像的尝试具有重要意义。

## 2. 回顾

在所有先前的研究中，对 ViT 最重要、产生的影响最深刻的无疑是 Transformer 模型的提出；在 NLP 领域，Transformer 迅速成为了最先进的方法。

而在 CV 领域中，很多人已经想到将 Transformer 以及自注意力机制与卷积神经网络架构相结合。Wang 等人（2018）和 Carion 等人（2020）尝试将类似卷积神经网络的架构与自注意力机制相结合，Ramachandran 等人（2019）和 Wang 等人（2020）则完全用自注意力机制取代卷积。但这些模型仅理论效率很高，由于采用了专门的注意力模式，尚未能在现代硬件加速器上实现有效扩展。

对于在图像处理问题中引入自注意力机制的尝试，如果将自注意力机制直接应用于图像，那么每个像素都需要关注其他所有像素，这会导致计算成本呈像素数量的平方增长，过高的计算成本会导致无法应用于实际的输入规模。因此，过去人们尝试了多种近似方法，具体来说：

* Parmar 等人（2018）提出了 *局部多头点积自注意力* 机制。只在每个查询像素的局部邻域内进行自注意力操作，替代了每个像素都和整张图像的所有像素进行自注意力计算的全局自注意力。
* Child 等人（2019）提出了 *稀疏 Transformer*。通过设计稀疏的注意力模式，让每个位置只与部分位置进行自注意力计算，而不是全部位置，借此近似实现全局自注意力。
* Weissenborn 等人（2019）提出了 *块状自注意力*。首先将图像划分为不同大小的块（patch），然后在每个块内进行自注意力计算。
* Ho 等人（2019）和 Wang 等人（2020）则采取了更极端的做法，只沿单个轴（如行或列）进行自注意力。

这些人的工作基本都聚焦于减少自注意力机制在图像上的计算量，使其能够高效地应用于视觉任务。但这些专门设计的注意力架构要在硬件加速器上高效实现，需要复杂的工程设计，且在硬件加速器上难以高效运行。

Cordonnier 等人（2020）则从输入图像上提取 2x2 大小的块，并在其上应用全注意力机制。但 2x2 的块尺寸过小，导致该模型只适用于低分辨率的图像，并且未能证明大规模预训练能够使普通的 Transformer 能够与最先进的 CNN 竞争，甚至将其超过。

Chen 等人（2020）提出的图像 GPT 模型在降低图像分辨率和颜色空间后将 Transformer 应用于图像，以无监督的方式作为生成模型进行训练，在预训练结束后既可以针对下游分类任务进行微调，也可以不改变模型参数进行线性探测。

## 3. 方法

论文的目的是为了探究将尽可能原始的 Transformer 架构用于 CV 领域的方法。考虑到 Transformer 的输入应当是序列的形式，研究人员必须构建一种将图像转化为序列的方法，这一方法主要包含两个步骤：图像分块和块嵌入。

首先将原始图像分割为一系列分辨率固定的小块，这篇论文的作者选取了 16x16 大小的小块，然后将这些小块展平，并通过一层全连接层将小块投射到 Transformer 预期接收的维度。

小块在原始图像中的位置在训练过程中是不可忽视的，为了保留每个小块的位置信息，作者引入了位置嵌入，利用一个具有一层隐藏层的 MLP 实现一个可学习的位置嵌入，并为每个小块加上其位置嵌入（作者经过实验发现更复杂的二位感知嵌入等位置嵌入并不能带来显著的训练效果提升，因此使用了基础的一维可学习位置嵌入）。

所有经过上述步骤的小块此时已经成为一组一维向量，这组向量构成的序列就是 Transformer 的输入，作者使用的 Transformer 编码器由多头自注意力层和 MLP 层交替组成，每个块之前应用层归一化，每个块之后应用残差连接。

对于模型的训练，作者首先在大数据集上对 ViT 进行预训练，然后针对规模较小的下游任务进行微调。

## 4. 实验

在实验过程中，作者采用了三个不同大小的数据集，分别是较小的 ImageNet，中等的 ImageNet-21K，较大的 JFT。在这三个数据集上分别训练 ResNet，ViT，混合架构以评估不同数据集大小下 ViT 与传统架构的的表现差异。对于这些数据集，预处理步骤遵循 Kolesnikov 等人(2020)的方法。

对于 ViT 架构，作者沿用 Devlin 等人（2019）在 BERT 所使用的配置构建了“基础”和“大型”模型，并额外增添了“巨型”模型。对于 CNN 架构，作者采用 He 等人（2016）的 ResNet 架构，为提升迁移性能，将批量归一层替换为组归一层，并采用标准化卷积。

模型的训练使用 Adam，β1 = 0.9，β2 = 0.999，批量大小为 4096，并应用 0.1 的高权重衰减，采用线性学习率预热和衰减；模型的微调使用带有动量的 SGD，批量大小为 512，对于较小的 ImageNet 数据集，改以更高的分辨率进行微调：ViT-L/16 为 512，ViT-H/14 为 518，并使用 Polyak & Juditsky 平均法，因子为 0.9999。

作者选取下游数据集上的微调准确率作为指标来报告结果，微调成本过高时，改为线性少样本准确率。

作者在相同的硬件条件和时间条件下将 ViT-H/14 和 ViT-L/16 与 BiT 和 Noisy Student 进行对比，分别在 ImageNet 和 JFT-300M 上使用半监督学习进行训练。

实验结果显示，在 JFT-300M 上进行预训练的 ViT-L/16 模型在所有任务上的表现均优于在相同数据集上进行预训练的 BiT-L 模型，且训练所需的计算资源大幅减少。ViT-H/14 模型进一步提升了性能，尤其是在更具挑战性的 ImageNet、CIFAR-100 和 VTAB 数据集上。

为了探究数据集规模的影响，作者又进行了两组实验，其一是在 ImageNet、ImageNet-21k 和 JFT300M 这三个逐渐增大的数据集上对不同大小的 ViT 进行训练；其二是在 900万、3000万、9000万的随机子集以及完整的 JFT-300M 数据集上对不同大小的 ViT 进行训练。

实验结果显示，在较小的数据集上，表现最好的依旧是传统 CNN 架构，随着数据集增大，ViT 更不容易达到性能瓶颈，表现更好。且大规模的 ViT 在较小的数据集上表现不如普通规模的 ViT，但在更大的数据集上会有更好的表现。

作者进行了扩展研究探究 ViT 的迁移性能，作者分别固定其他条件，只改变模型参数量、patch 大小或训练集规模，试验结果表明模型规模增大和数据集增大都可以提升 ViT 性能，且未发现明显饱和，但过大过小的 patch 都会使模型性能下降。

作者还尝试用自我监督任务对 ViT 进行预训练，结果优于未进行预训练的 ViT，但不如有监督预训练的 ViT。

## 5. 点评

### 5.1. 优势

* **创新性强** 在前人研究对图像应用自注意力机制的基础上，首次设计出先将图像转换为序列再利用经典 Transformer 架构对其应用自注意力机制的方法，在 CV 领域首次有效应用了原始 Transformer 架构。

* **通用性强** 作者设计的 ViT 架构直接利用了原始的、未经任何特殊设计的 Transformer 架构，不依赖于卷积操作或特定于视觉任务的结构调整，使得该结构具有很强的通用性和迁移性。在预训练后可以很方便地投入下游任务。

* **实验严谨** 在实验的设计中，对于不同大小的数据集，作者采用了不同的数据处理和正则化方法，并选择了不同的指标，使得每一组实验的指标都很好地反映了模型在该条件下所能达到的真实且最好的表现，得出的结论也更加准确可信。

* **方法简单** 提出的*图像分块+块嵌入*的图像处理方法简洁明了，易于理解，便于后来的研究者对其进行改进与优化。

### 5.2. 不足

* **数据集规模过大** 模型主要在超大规模的数据集上进行训练，缺少对于更小规模数据集上表现的讨论。

* **实验复现难度大** 大规模的数据集和模型导致实验对算力要求极大，使得实验复现难度较高。

* **原理讨论较少** 对于实验结果并未深入讨论可能的成因，主要聚焦于对实验结果的分析，讨论模型表现的差异。

**实验复现难度大** 大规模的数据集和模型导致实验对算力要求极大，使得实验复现难度较高。

**原理讨论较少** 对于实验结果并未深入讨论可能的成因，主要聚焦于对实验结果的分析，讨论模型表现的差异。

